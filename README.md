# ğŸ—ï¸ IronSite BuilderBobs â€” AI Construction Productivity Pipeline

> **Hackathon Project â€” February 2026**  
> Analyze construction worker body-cam footage with computer vision + AI vision models to power a real-time supervisor dashboard.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io)

---

## Overview

BuilderBobs is a **two-stage AI pipeline** that processes first-person (POV) body-camera footage from construction workers:

| Stage | Technology | Output |
|-------|-----------|--------|
| **1 â€” Quantitative** | OpenCV Â· MediaPipe Â· YOLOv8 | Productivity %, Peak Exertion, Annotated Video |
| **2 â€” Qualitative** | Ollama LLaVA 7B (remote GPU) | Trade ID, Task Description, Universal Efficiency Score |

Both stages feed a unified **Streamlit supervisor dashboard**.

---

## Architecture

```
ğŸ“¹ Raw Body-Cam MP4s
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1 Â· first_person_pipeline.py â”‚
â”‚  â€¢ MediaPipe wrist tracking (5 FPS) â”‚
â”‚  â€¢ YOLOv8 construction objects      â”‚
â”‚  â€¢ Global motion compensation       â”‚
â”‚  â€¢ Activity classification          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚  master_dashboard.csv
                â”‚  outputs/*_plot.png
                â”‚  outputs/*_annotated.mp4
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2 Â· agent_video_analyzer.py  â”‚
â”‚  â€¢ SSH tunnel â†’ Ollama LLaVA (GPU)  â”‚
â”‚  â€¢ 16 frames sampled by ffmpeg      â”‚
â”‚  â€¢ Structured JSON response         â”‚
â”‚  â€¢ AI_Trade, AI_UES, AI_Summary     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚  outputs/Agent_Analysis_*.json
                â”‚  master_dashboard.csv (enriched)
                â–¼
        ğŸ–¥ï¸  dashboard.py (Streamlit)
```

---

## Results (14 Videos Processed)

| Metric | Value |
|--------|-------|
| Average Productivity | **91.9%** |
| Average AI Efficiency (UES) | **85.4 / 100** |
| Site Peak Exertion | **83.84 px** |
| Trades Identified | Construction Workers (11), Plumbers (3) |
| Stage 2 Processing Speed | **~8 seconds/video** on GPU |

---

## Project Structure

```
â”œâ”€â”€ first_person_pipeline.py     # Stage 1: OpenCV batch processor
â”œâ”€â”€ agent_video_analyzer.py      # Stage 2: Ollama LLaVA vision agent
â”œâ”€â”€ batch_agent_analysis.py      # Runs Stage 2 across all videos
â”œâ”€â”€ dashboard.py                 # Streamlit supervisor dashboard
â”œâ”€â”€ analyze_results.py           # Gemini text-based site report (legacy)
â”œâ”€â”€ apply_global_motion.py       # Camera-shake compensation utility
â”œâ”€â”€ recalculate_metrics.py       # Recalculate metrics from existing CSVs
â”œâ”€â”€ master_dashboard.csv         # Aggregated metrics (both stages)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ Agent_Analysis_*.json    # Per-video AI analysis
â”‚   â”œâ”€â”€ *_plot.png               # Exertion time-series plots
â”‚   â”œâ”€â”€ *_data.csv               # Per-frame exertion data
â”‚   â””â”€â”€ Final_AI_Site_Report.txt # Text-based executive summary
â”œâ”€â”€ hand_landmarker.task         # MediaPipe model
â”œâ”€â”€ yolov8n-construction.pt      # Custom YOLOv8 construction model
â””â”€â”€ IronsiteHackathonData/       # Raw MP4s (gitignored)
```

---

## Setup & Execution

### Requirements

```bash
pip install -r requirements.txt
# Also requires: ffmpeg, opencv-python, mediapipe, ultralytics
```

### Stage 1 â€” OpenCV Pipeline

```bash
# Place raw .mp4 files in IronsiteHackathonData/
python3 first_person_pipeline.py
```

Outputs to `outputs/` and writes `master_dashboard.csv`.

### Stage 2 â€” AI Vision Agent (Ollama LLaVA)

Requires a running Ollama instance with `llava:latest`. Using Vast.ai remote GPU:

```bash
# 1. Start SSH tunnel (maps remote Ollama to localhost:11434)
ssh -p 56834 root@YOUR_VAST_IP -L 8080:localhost:11434

# 2. Set env var (or edit .env)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_VISION_MODEL=llava:latest

# 3. Run batch analysis
python3 batch_agent_analysis.py
```

To process a single video:
```bash
python3 agent_video_analyzer.py IronsiteHackathonData/14_production_mp.mp4
```

### Launch Dashboard

```bash
streamlit run dashboard.py
# â†’ http://localhost:8501
```

### Deploy to Streamlit Community Cloud

1. Push repo to GitHub (already done âœ…)
2. Go to [share.streamlit.io](https://share.streamlit.io) â†’ **New app**
3. Select repo `sujeetmadihalli/Hackathon_BuilderBobs` Â· branch `main` Â· file `dashboard.py`
4. Click **Deploy**

---

## AI Analysis Output Schema

Each video produces an `outputs/Agent_Analysis_{video}.json`:

```json
{
  "primary_trade": "Plumber",
  "specific_tasks": "Fixing pipes, cutting materials",
  "quantified_output": "10 joints welded, 2 pipes cut",
  "universal_efficiency_score": 96,
  "performance_summary": "The plumber demonstrates high physical exertion and efficiency in completing the tasks at hand."
}
```

---

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Computer Vision | OpenCV, MediaPipe HandLandmarker, YOLOv8 |
| AI Vision Model | Ollama LLaVA 7B (self-hosted on Vast.ai) |
| Frame Extraction | ffmpeg |
| Dashboard | Streamlit + Altair |
| Data | pandas, CSV |
| Remote GPU | Vast.ai (SSH tunnel) |
| Deployment | Streamlit Community Cloud |

---

*BuilderBobs Â· IronSite Hackathon 2026*
